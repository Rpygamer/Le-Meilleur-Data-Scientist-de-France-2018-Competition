{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-25T07:35:43.334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good luck\n",
      "loading train data...\n",
      "loading test data...\n",
      "hour, day, wday....\n",
      "grouping by ip-day-hour combination....\n",
      "group by ip-app combination....\n",
      "group by ip-app-os combination....\n",
      "vars and data type....\n",
      "label encoding....\n",
      "final part of preparation....\n",
      "neural network....\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "app (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ch (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dev (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "os (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h (InputLayer)                  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "d (InputLayer)                  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wd (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "qty (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c1 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c2 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 50)        38450       app[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 50)        25050       ch[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 50)        211400      dev[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 50)        47850       os[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 50)        1200        h[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 1, 50)        550         d[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 50)        250         wd[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 50)        2213000     qty[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 50)        3260550     c1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 50)        2758000     c2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 500)       0           embedding_11[0][0]               \n",
      "                                                                 embedding_12[0][0]               \n",
      "                                                                 embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "                                                                 embedding_15[0][0]               \n",
      "                                                                 embedding_16[0][0]               \n",
      "                                                                 embedding_17[0][0]               \n",
      "                                                                 embedding_18[0][0]               \n",
      "                                                                 embedding_19[0][0]               \n",
      "                                                                 embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1, 500)       0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 100)       200100      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 500)          0           spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 100)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 600)          0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 700)          420700      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 700)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1000)         701000      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1000)         0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 400)          400400      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 100)          40100       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 100)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            101         dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,318,701\n",
      "Trainable params: 10,318,701\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "# good day, my friends\n",
    "# in this kernel we try to continue development of our DL models\n",
    "# thanks for people who share their works. i hope together we can create smth interest\n",
    "\n",
    "# https://www.kaggle.com/baomengjiao/embedding-with-neural-network\n",
    "# https://www.kaggle.com/gpradk/keras-starter-nn-with-embeddings\n",
    "# https://www.kaggle.com/pranav84/lightgbm-fixing-unbalanced-data-auc-0-9787\n",
    "# https://www.kaggle.com/rteja1113/lightgbm-with-count-features\n",
    "# https://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl\n",
    "# https://www.kaggle.com/isaienkov/rnn-with-keras-ridge-sgdr-0-43553\n",
    "# https://www.kaggle.com/valkling/mercari-rnn-2ridge-models-with-notes-0-42755/versions#base=2202774&new=2519287\n",
    "\n",
    "\n",
    "#======================================================================================\n",
    "# we continue our work started in previos kernel \"Deep learning support..\"\n",
    "# + we will try to find a ways which can help us increase specialisation of neural network on our task\n",
    "# + we will try to work with different architect decisions for neural networks\n",
    "# if you need a details about what we try to create follow the comments\n",
    "\n",
    "print ('Good luck')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '14'\n",
    "import gc\n",
    "\n",
    "path = '../input/'\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "print('loading train data...')\n",
    "train_df = pd.read_csv(\"./train.csv.zip\",compression='zip',parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n",
    "\n",
    "print('loading test data...')\n",
    "\n",
    "test_df = pd.read_csv(\"./test.csv.zip\", compression='zip',parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "\n",
    "len_train = len(train_df)\n",
    "train_df=train_df.append(test_df)\n",
    "del test_df\n",
    "gc.collect()\n",
    "\n",
    "print('hour, day, wday....')\n",
    "train_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('uint8')\n",
    "train_df['day'] = pd.to_datetime(train_df.click_time).dt.day.astype('uint8')\n",
    "train_df['wday']  = pd.to_datetime(train_df.click_time).dt.dayofweek.astype('uint8')\n",
    "print('grouping by ip-day-hour combination....')\n",
    "gp = train_df[['ip','day','hour','channel']].groupby(by=['ip','day','hour'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'qty'})\n",
    "train_df = train_df.merge(gp, on=['ip','day','hour'], how='left')\n",
    "del gp; gc.collect()\n",
    "print('group by ip-app combination....')\n",
    "gp = train_df[['ip','app', 'channel']].groupby(by=['ip', 'app'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_count'})\n",
    "train_df = train_df.merge(gp, on=['ip','app'], how='left')\n",
    "del gp; gc.collect()\n",
    "print('group by ip-app-os combination....')\n",
    "gp = train_df[['ip','app', 'os', 'channel']].groupby(by=['ip', 'app', 'os'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_os_count'})\n",
    "train_df = train_df.merge(gp, on=['ip','app', 'os'], how='left')\n",
    "del gp; gc.collect()\n",
    "print(\"vars and data type....\")\n",
    "train_df['qty'] = train_df['qty'].astype('uint16')\n",
    "train_df['ip_app_count'] = train_df['ip_app_count'].astype('uint16')\n",
    "train_df['ip_app_os_count'] = train_df['ip_app_os_count'].astype('uint16')\n",
    "\n",
    "print(\"label encoding....\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_df[['app','device','os', 'channel', 'hour', 'day', 'wday']].apply(LabelEncoder().fit_transform)\n",
    "print ('final part of preparation....')\n",
    "test_df = train_df[len_train:]\n",
    "train_df = train_df[:len_train]\n",
    "y_train = train_df['is_attributed'].values\n",
    "train_df.drop(['click_id', 'click_time','ip','is_attributed'],1,inplace=True)\n",
    "\n",
    "print ('neural network....')\n",
    "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers import BatchNormalization, SpatialDropout1D, Conv1D\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "max_app = np.max([train_df['app'].max(), test_df['app'].max()])+1\n",
    "max_ch = np.max([train_df['channel'].max(), test_df['channel'].max()])+1\n",
    "max_dev = np.max([train_df['device'].max(), test_df['device'].max()])+1\n",
    "max_os = np.max([train_df['os'].max(), test_df['os'].max()])+1\n",
    "max_h = np.max([train_df['hour'].max(), test_df['hour'].max()])+1\n",
    "max_d = np.max([train_df['day'].max(), test_df['day'].max()])+1\n",
    "max_wd = np.max([train_df['wday'].max(), test_df['wday'].max()])+1\n",
    "max_qty = np.max([train_df['qty'].max(), test_df['qty'].max()])+1\n",
    "max_c1 = np.max([train_df['ip_app_count'].max(), test_df['ip_app_count'].max()])+1\n",
    "max_c2 = np.max([train_df['ip_app_os_count'].max(), test_df['ip_app_os_count'].max()])+1\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'app': np.array(dataset.app),\n",
    "        'ch': np.array(dataset.channel),\n",
    "        'dev': np.array(dataset.device),\n",
    "        'os': np.array(dataset.os),\n",
    "        'h': np.array(dataset.hour),\n",
    "        'd': np.array(dataset.day),\n",
    "        'wd': np.array(dataset.wday),\n",
    "        'qty': np.array(dataset.qty),\n",
    "        'c1': np.array(dataset.ip_app_count),\n",
    "        'c2': np.array(dataset.ip_app_os_count)\n",
    "    }\n",
    "    return X\n",
    "train_df = get_keras_data(train_df)\n",
    "\n",
    "emb_n = 50\n",
    "dense_n = 700\n",
    "in_app = Input(shape=[1], name = 'app')\n",
    "emb_app = Embedding(max_app, emb_n)(in_app)\n",
    "in_ch = Input(shape=[1], name = 'ch')\n",
    "emb_ch = Embedding(max_ch, emb_n)(in_ch)\n",
    "in_dev = Input(shape=[1], name = 'dev')\n",
    "emb_dev = Embedding(max_dev, emb_n)(in_dev)\n",
    "in_os = Input(shape=[1], name = 'os')\n",
    "emb_os = Embedding(max_os, emb_n)(in_os)\n",
    "in_h = Input(shape=[1], name = 'h')\n",
    "emb_h = Embedding(max_h, emb_n)(in_h) \n",
    "in_d = Input(shape=[1], name = 'd')\n",
    "emb_d = Embedding(max_d, emb_n)(in_d) \n",
    "in_wd = Input(shape=[1], name = 'wd')\n",
    "emb_wd = Embedding(max_wd, emb_n)(in_wd) \n",
    "in_qty = Input(shape=[1], name = 'qty')\n",
    "emb_qty = Embedding(max_qty, emb_n)(in_qty) \n",
    "in_c1 = Input(shape=[1], name = 'c1')\n",
    "emb_c1 = Embedding(max_c1, emb_n)(in_c1) \n",
    "in_c2 = Input(shape=[1], name = 'c2')\n",
    "emb_c2 = Embedding(max_c2, emb_n)(in_c2) \n",
    "fe = concatenate([(emb_app), (emb_ch), (emb_dev), (emb_os), (emb_h), \n",
    "                 (emb_d), (emb_wd), (emb_qty), (emb_c1), (emb_c2)])\n",
    "s_dout = SpatialDropout1D(0.2)(fe)\n",
    "fl1 = Flatten()(s_dout)\n",
    "conv = Conv1D(100, kernel_size=4, strides=1, padding='same')(s_dout)\n",
    "fl2 = Flatten()(conv)\n",
    "concat = concatenate([(fl1), (fl2)])\n",
    "x = Dropout(0.2)(Dense(100,activation='relu')(concat))\n",
    "x = Dropout(0.3)(Dense(200,activation='relu')(x))\n",
    "x = Dropout(0.3)(Dense(400,activation='relu')(x))\n",
    "x = Dropout(0.2)(Dense(100,activation='relu')(x))\n",
    "outp = Dense(1,activation='sigmoid')(x)\n",
    "model = Model(inputs=[in_app,in_ch,in_dev,in_os,in_h,in_d,in_wd,in_qty,in_c1,in_c2], outputs=outp)\n",
    "\n",
    "batch_size = 1000000\n",
    "epochs = 5\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(list(train_df)[0]) / batch_size) * epochs\n",
    "lr_init, lr_fin = 0.002, 0.0002\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "optimizer_adam = Adam(lr=0.002, decay=lr_decay)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer_adam,metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "class_weight = {0:.01,1:.99} # magic\n",
    "model.fit(train_df, y_train, batch_size=batch_size, epochs=5, class_weight=class_weight, shuffle=True, verbose=2)\n",
    "del train_df, y_train; gc.collect()\n",
    "model.save_weights('imbalanced_data.h5')\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = test_df['click_id'].astype('int')\n",
    "test_df.drop(['click_id', 'click_time','ip','is_attributed'],1,inplace=True)\n",
    "test_df = get_keras_data(test_df)\n",
    "\n",
    "print(\"predicting....\")\n",
    "sub['is_attributed'] = model.predict(test_df, batch_size=batch_size, verbose=2)\n",
    "del test_df; gc.collect()\n",
    "print(\"writing....\")\n",
    "sub.to_csv('NN_1.csv',index=False)\n",
    "\n",
    "\n",
    "# write now i don't use validation set\n",
    "# since the data is imbalanced i can't understand how we can separate data the right way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
